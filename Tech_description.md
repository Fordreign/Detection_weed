Для начала хотелось бы поблагодарить ребят из [ultralytics](https://github.com/ultralytics) за открытый код и готовое решение с встроенным API.
# Модель
YOLOv8 состоит из двух основных компонентов:

Bottleneck (Основа):

Bottleneck  в YOLOv8 представляет собой модифицированный вариант Feature Pyramid Network (FPN).
Он выполняет операцию объединения признаков, используя skip-соединения между различными слоями сети.
Благодаря этому, информация о признаках с разных уровней сети объединяется, что позволяет лучше захватить пространственные и семантические информации на разных масштабах и разрешениях.

Head (Голова):

Голова в YOLOv8 отвечает за вывод предсказаний объектов на основе обработанных признаков из предыдущих модулей.
Она состоит из одной головы вывода (output head), которая предсказывает координаты ограничивающих рамок, вероятности классов и оценки уверенности (confidence scores).
Голова использует механизм анкерных рамок (anchor boxes), который представляет собой предопределенные рамки с фиксированными размерами и соотношениями сторон. Модель предсказывает координаты анкерных рамок и корректирует их, чтобы точно соответствовать объекту на изображении.

![image](https://github.com/Fordreign/Tg_bot_detection_weed/assets/69246960/629b0624-b97b-4c95-b554-2bb1239eaef0)картинка взята из [ресурса](https://github.com/ultralytics/ultralytics/issues/189)
# Метрики
**IoU**

![image](https://github.com/Fordreign/Tg_bot_detection_weed/assets/69246960/2dbfcd8d-265c-4a34-8b9c-d60373a902bf)
[resource](https://pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/)

Чтобы определить точность, нам нужно определить истинно положительные и ложно положительные результаты для обнаружения объектов. Истинно положительный (TP) результат определяется, когда IoU между предсказанной рамкой и истинной рамкой больше заданного порога IoU, тогда как ложно положительный (FP) результат имеет IoU ниже этого порога, а ложно отрицательный (FN), когда мы не попали предсказанной рамкой по истинной. . Затем точность может быть определена как TP/(TP + FP).

![image](https://github.com/Fordreign/Tg_bot_detection_weed/assets/69246960/f56e950b-25ec-4e4d-a3f7-136211a5c231)

[resource](https://github.com/Fordreign/Tg_bot_detection_weed/assets/69246960/f56e950b-25ec-4e4d-a3f7-136211a5c231)

Для вычисления среднего среднего значения точности (mAP) мы выполняем следующие шаги:

Для каждого класса проводим оценку точности (AP) при различных порогах пересечения/объединения (IoU).
* Мы начинаем с порога IoU 0,5 и постепенно увеличиваем его на 0,05 до достижения значения 0,95.
* Для каждого порога IoU вычисляем точность (AP) для каждого класса.
* Усредняем точности (AP) для каждого класса по всем порогам IoU, чтобы получить среднюю точность (AP) для этого класса.

Ниже видео для общего понимания

[AP](https://github.com/Fordreign/Tg_bot_detection_weed/assets/69246960/66d13ac0-fb24-4850-88a2-31c019805147)

[resource](https://blog.roboflow.com/mean-average-precision/)

Для mAP50-95:

* Повторяем шаги 3-4 для каждого класса в наборе данных.
* Усредняем средние точности (AP) для всех классов, чтобы получить mAP50-95.
* Таким образом, mAP50-95 представляет собой среднюю точность по всем классам на интервале порогов IoU от 0,5 до 0,95 с шагом 0,05.

![image](https://github.com/Fordreign/Tg_bot_detection_weed/assets/69246960/3a6da4e2-2fdd-45c9-82aa-873f350685c7)
# Функции потерь
Функция потерь для модели YOLOv8 состоит из трех частей: потери рамки, потери классификации и потери распределения фокуса. Давайте рассмотрим каждую часть по отдельности:

Потеря рамки (box loss):

Эта часть функции потерь оценивает, насколько точно модель предсказывает рамку, ограничивающую объект.
Она использует понятие IoU (пересечение по площади / объединение по площади), чтобы сравнить предсказанную рамку с истинной рамкой объекта.
Чем меньше расхождение между предсказанной и истинной рамкой (чем выше IoU), тем меньше будет потеря рамки.

Потеря классификации (classification loss):

Эта часть функции потерь оценивает, насколько точно модель предсказывает класс объекта в каждой ячейке сетки.
Она использует бинарную перекрестную энтропию для сравнения предсказанной вероятности класса с истинной меткой класса.
Чем меньше расхождение между предсказанной вероятностью и истинной меткой класса, тем меньше будет потеря классификации.

Потеря распределения фокуса (distribution focal loss):

Эта часть отвечает за обучение модели предсказывать объекты разных размеров и ориентаций.
Она включает в себя два компонента: первый компонент измеряет разницу между предсказанными значениями IoU для соседних рамок объекта, а второй компонент измеряет разницу между предсказанными значениями IoU их соседей для каждой ячейки сетки.

Каждая часть функции потерь вносит свой вклад в общую потерю модели, и цель состоит в том, чтобы минимизировать эту общую потерю путем обучения модели на обучающих данных.


L = <sup>λ<sub>box</sub></sup>&frasl;<sub>N<sub>pos</sub></sub> &sum;<sub>x,y</sub> (1<sub>c∗</sub>x,y * (1−q<sub>x,y</sub> + 
(k<sub>b</sub>x,y − ˆb<sub>x,y</sub>)<sup>2</sup> &frasl; ρ<sup>2</sup>) + α<sub>x,y</sub>ν<sub>x,y</sub>) "box_loss"
 
 +<sup>λ<sub>cls</sub></sup>&frasl;<sub>N<sub>pos</sub></sub> &sum;<sub>x,y</sub> &sum;<sub>c∈classes</sub> (y<sub>c</sub> * log(ˆy<sub>c</sub>) +(1 − y<sub>c</sub>) * log(1 − ˆy<sub>c</sub>))       "cl_loss"
 
 +<sup>λ<sub>df l</sub></sup>&frasl;<sub>N<sub>pos</sub></sub> &sum;<sub>x,y</sub> (1<sub>c∗</sub>x,y * h * (− (q<sub>x,y</sub>+1 − q<sub>x,y</sub>) * log(ˆq<sub>x,y</sub>) + (q<sub>x,y</sub> − q<sub>x,y</sub>−1) * log(ˆq<sub>x,y</sub>+1))) "dfl_loss"
<p>where:</p>
<ul>
  <li>qx,y = IoUx,y = <sup>βˆx,y ∩ βx,y</sup>&frasl;<sub>βˆx,y ∪ βx,y</sub></li>
  <li>νx,y = <sup>4π</sup>&frasl;<sub>2</sub> (arctan(<sup>wx,y</sup>&frasl;<sub>hx,y</sub>) − arctan(<sup>wˆx,y</sup>&frasl;<sub>hˆx,y</sub>))<sup>2</sup></li>
  <li>αx,y = <sup>ν</sup>&frasl;<sub>1 − qx,y</sub></li>
  <li>yˆc = σ(·)</li>
  <li>qˆx,y = softmax(·)</li>
</ul>
# Обучение и валидация


# Cituation
[arxiv](https://arxiv.org/pdf/2305.09972.pdf)
